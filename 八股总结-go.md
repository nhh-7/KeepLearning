## GO



### -------------------------------------------------



### 三次握手

- 客户端发送SYN报文，初始化序列号，进入SYN_SEND
- 服务端发送 SYN+ACK报文，初始自己的序列号，进入SYN_RECV
- 客户端发送ACK报文，客户端进入ESTABLISHED，服务端收到这个ACK后，也进入ESTABLISHED
- 四次多余，两次会导致服务端资源的浪费，每收到一个SYN就建立一个连接

### 四次挥手

- 客户端发送FIN报文，进入FIN-WAIT-1
- 服务端回复ACK，服务端进入CLOSE-WAIT，客户端收到后进入FIN_WAIT-2
- 服务端可继续发送数据
- 服务端发送FIN，进入LAST-ACK
- 客户端回复ACK，客户端进入TIME-WAIT，服务端收到后进入CLOSE

- 为什么要四次？
  - TCP 是全双工协议，需分别关闭两个方向的连接。
  - 被动关闭方可能需要时间处理剩余数据，不能立即发送 `FIN`。

- 为什么客户端要等待2MSL？MSL - 报文最大生存时间
  - 确保最后一个ACK报文能够到达服务器，ACK如果丢失，服务器收不到ACK，超时重传，客户端收到后重新发送
  - 确保在本连接持续期间所产生的所有报文段都从网络中消失，从而避免新旧连接之间的干扰‌

### 流量控制

- 防止发送方**发送速率过快**导致接收方缓冲区溢出。
- **核心机制**：滑动窗口 -  接收方通过 TCP 报文段中的**窗口字段（Window Size）** 告知发送方自己当前的接收缓冲区可用空间，发送方据此限制发送数据的大小。

### 拥塞控制

避免网络因**过量数据**导致拥堵，通过动动态调整发送方的**拥塞窗口**平衡全局负载， 

- 慢启动 -- 收到一个ACK，拥塞窗口就指数增长，超过阈值，进入下一阶段
- 拥塞避免--线性增长，
- 快速重传--收到三个重复ACK，立即重传丢失的报文，无需等待超时。
- 快速恢复 -- 重传后，将阈值设为当前拥塞窗口 的一半。拥塞窗口设为阈值，并进入拥塞避免阶段

### TCP与UDP对比

- TCP面向连接，UDP无连接
- TCP可靠传输，通过握手、确认、重传、拥塞控制机制。UDP不可靠传输、不保证数据不丢失
- TCP有状态、会记录消息是否发送、是否被接收等、UDP无状态
- TCP面向字节流、UDP面向报文
- TCP传输效率低
- TCP首部开销 20~60字节，比UDP首部 8 字节大
- TCP只支持点对点通信，UDP支持广播或多播
- 使用场景
  - TCP：要求通信数据可靠场景 -- 网页浏览、文件传输、邮件传输
  - UDP：要求通信速度⾼场景  --  域名转换、视频直播、实时游戏

### TCP确保可靠

- 为每个数据包指定序号
- 校验和，校验首部和数据部分，接收端计算检验和，若改变了，则丢弃
- 流量控制：TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据
- 拥塞控制
- 确认应答
- 超时重传

### KeepAlive

- TCP的Keepalive：⼀种⽤于在 TCP 连接上检测空闲连接状态的机制，就是TCP有⼀个定时任务做倒计时，超时后会触发任务，内容是发送⼀个探测报⽂给对端，⽤来判断对端是否存活。  
- HTTP的Keep-Alive：用于设置开启长连接

### 强缓存和协商缓存

- 强缓存：服务端返回资源时带上一个过期时间字段，当客户端再次访问资源，浏览器判断是否已经过期，未过期可直接读取缓存
- 协商缓存：客户端第一次访问资源，服务端会根据该文件生成一个表示文件是否改动了的标志（last-modified返回文件修改时间，`ETag`返回文件哈希值），客户端将资源缓存，后续客户端访问该资源时，会先发送该标志给服务端，服务器判断资源是否修改，未修改客户端可直接读取缓存。

### HTTP迭代

- HTTP 0.9 ：只支持GET方法，没有请求头
- HTTP 1.0 ：引入请求头和响应头，只能短连接，每次请求都要建立一个TCP连接
- HTTP 1.1 ： 支持长连接，管道化使得请求能够并行发送（也就是发送请求后，不必收到回应就继续发送请求），Host字段在同一个`IP`地址上承载多个域名
- HTTP 2 ：基于HTTPS，将数据分割为二进制帧进行传输，多路复用 -- 同一个HTTP连接发起多个请求-响应，首部压缩（`HPACK`算法），服务器可以自主向客户端推送资源
- HTTP 3 ：基于 `QUIC` 协议构建，使用 `UDP` 作为传输层协议，HTTP/3 继承并优化了 HTTP/2 的多路复用特性

### 如何建立HTTPS连接 

1. 客户端发送请求
2. 服务端生成一对公私钥，公钥传给CA机构，CA机构使用自己的私钥对服务器公钥加密，生成数字证书
3. 服务器将数字证书传回客户端
4. 客户端浏览器解析数字证书，得到服务端的公钥
5. 客户端随机生成一个密钥，用服务器公钥加密，传给服务器
6. 服务器使用自己的私钥解密，得到客户端的密钥
7. 两端使用这个密钥进行加密解密通信

### GET和POST请求的区别  

- GET⽤于从服务端获取资源， POST用来向服务器端提交数据
- GET请求的参数一般写在URL中，POST请求参数放在请求体
- 安全性不同
- GET 请求会被浏览器主动cache，⽽ POST 不会，除⾮⼿动设置。  

### 在浏览器中输入URL

结合网络模型：

1. 浏览器根据 URL 确定要访问的资源，并构建 HTTP 请求报文
2. 浏览器根据URL解析出域名，并检查缓存中是否有对应IP地址，没有则向 DNS 服务器发送域名解析请求，将域名转换为 IP 地址。
3. TCP开始三次握手，将应用层的 HTTP 请求报文封装成 TCP 报文段，添加源端口和目的端口等信息。如果是 HTTP/3 版本，会使用 UDP 协议并结合 QUIC 等机制来提高性能。
4. 将 TCP 报文段（或 UDP 数据报）封装成 IP 数据包，添加源 IP 地址和目的 IP 地址。
5. 构建数据包时，已知目标 IP 地址。通过查找本地路由表，判断目标 IP 是否在本地子网。若不在，选择默认网关作为中间跳点。
6. 将 IP 数据包封装成帧，添加源 MAC 地址和目的 MAC 地址等链路层头部信息，根据ARP协议，通过下一跳IP地址得到MAC地址。

不结合分层模型：

1. 浏览器会解析出协议、主机、端⼝、路径等信息，并构造⼀个HTTP请求  
2. DNS域名解析, 将域名解析成对应的IP地址  
3. 建⽴起TCP连接之三次握⼿  
4. 浏览器发送HTTP/HTTPS请求到web服务器  
5. 服务器处理HTTP请求并返回HTTP报⽂  
6. 浏览器渲染⻚⾯  
7. 断开连接之TCP四次挥⼿ 

### DNS查询过程 -- 客户端向本地域名服务器发起递归查询，其余过程都是迭代查询

1.  浏览器缓存
2.  本地的host文件
3.  向本地DNS服务器发送查询请求
4.  本地DNS服务器向根域名服务器查询，根域名服务器不进行解析，而是告知向哪个顶级域名服务器继续查询
5.  本地DNS服务器继续向顶级域名服务器查询，后者告知向哪个权威域名服务器查询
6.  本地DNS服务器向该权威域名服务器继续查询，得到对应IP地址。

### CDN

全称为内容分发⽹络 （Content Delivery Network） , 通过将内容存储在分布式的服务器上，使⽤户可以从距离较近的服务器获取所需的内容，从⽽减少数据传输的时间和距离，提⾼内容的传输速度、减少延迟和提升⽤户体验。  

### SYN攻击

攻击者伪造不同IP地址的SYN报⽂请求连接，服务端收到连接请求后分配资源，回复ACK+SYN包，但是由于IP地址是伪造的，⽆法收到回应，久⽽久之造成服务端半连接队列被占满，⽆法正常⼯作。  

### -------------------------------------------------



### 操作系统进程通信

- 管道 -- 仅用于父子进程
- 命名管道 -- 允许⽆亲缘关系进程间的通信。  
- 消息队列 -- 消息队列是消息的链表，存放在内核中并由消息队列标识符标识  
- 共享内存  --  就是映射⼀段能被其他进程所访问的内存，这段共享内存由⼀个进程创建，但多个进程都可以访问。
- 信号量
- 信号
- 套接字 -- 主要⽤于在客户端和服务器之间通过⽹络进⾏通信。

### 操作系统内存管理

- 内存分配方式

  - 分页
  - 分段
  - 段页式

- 虚拟内存 -- 为进程提供**独立虚拟地址空间**，物理内存作为缓存，磁盘作为后备存储。

  - 页面置换算法

    最优置换

    先进先出

    最近最少使用

    时钟算法

  - 缺页中断

### 进程同步与异步

- 同步--互斥锁、条件变量、原子操作
- 异步
  - std::future -- 分离任务执行与结果获取，避免阻塞主线程。
  - 异步回调--任务完成后触发回调函数

### 进程、线程、协程

- 进程：操作系统资源分配的基本单位，包含独立的地址空间、代码段、数据段和系统资源（如文件句柄、内存空间）
- 线程：进程内的执行单元，共享进程的地址空间和系统资源（如内存、文件句柄）。线程是 CPU 调度的基本单位，同一进程内的线程可并发执行，减少了进程间切换的开销（进程切换需要切换地址空间、页表等操作、开销大）。
- 协程：又称 “用户态线程”，是由用户空间管理的轻量级执行单元。适合于高并发IO场景。

协程相比于线程的优势：

- 协程在用户态调度，开销小
- 协程的内存占用极小
- 线程需要操作系统内核维护线程控制块、调度队列等资源，而协程不占用内核资源。

### 读写锁的实现

允许多个线程同时读取共享资源（读锁可重入），但在写入时需要独占访问（写锁排他）。这种设计提高了并发性能，适合读多写少的场景。

- **状态跟踪**：通常使用一个计数器记录当前读者数量，以及一个标志位表示是否有写者等待或持有锁。
- **互斥锁**：保护内部状态变量的访问，确保操作的原子性。
- **条件变量**：用于线程间的通知机制，当写锁释放时通知等待的读者 / 写者。
- **读锁获取**：如果没有写者持有锁或等待，允许获取读锁并增加读者计数。
- **读锁释放**：减少读者计数，若减为 0 则通知可能等待的写者。
- **写锁获取**：等待直到没有读者和写者，然后标记写锁被持有。
- **写锁释放**：标记写锁释放，并通知所有等待的读者和写者。

### 内存对齐

内存管理中的一种优化技术，它确保数据在内存中的起始地址是特定值的整数倍

- 结构体的对齐值：取其数据成员中的最大对齐值
- CPU通常以固定大小的块（4字节、8字节）访问内存，如果未对齐，我们要用访问两次内存的值才能拼接成结果

### 僵尸进程与孤儿进程

- 僵尸进程：进程已终止后，但父进程尚未调用`wait()`或`waitpid()`获取其退出状态，此时进程描述符（PCB）仍保留在系统中，成为僵尸进程。父进程终止后，僵尸进程会被 init 接管并清除。
- 孤儿进程：父进程先于子进程终止，导致子进程成为 “孤儿”，此时子进程会被**init 进程（PID=1）或 systemd 进程**收养。

### 父子进程共享什么资源

- 代码段
- 文件描述符
- 信号处理函数
- 继承父进程的权限

### 没有虚拟内存的问题

- 每个进程必须完全加载到物理内存中，若程序所需内存超过物理 RAM 容量，则无法运行
- 系统同时运行的进程总数受限于物理内存大小
- 进程地址空间不隔离：每个进程直接访问物理内存，一个进程可通过错误指针覆盖其他进程的数据，导致系统不稳定。
- 虚拟内存通过页表实现内核空间与用户空间的隔离，无虚拟内存时，用户程序可能直接访问内核区域。

### 内部碎片与外部碎片

- 内部碎片：当内存分配的空间大于进程实际需要的空间时，多余的部分无法被其他进程使用，从而形成 “内部” 的空闲碎片。
- 外部碎片：内存中存在多个分散的空闲内存块，但它们的总大小足够满足进程需求，却因不连续而无法分配

### 用户态与核心态

- ⽤户态：在⽤户态下，进程或程序只能访问受限的资源和执⾏受限的指令集，不能直接访问操作系统的核⼼部分，也不能直接访问硬件资源。
- 核⼼态：核⼼态是操作系统的特权级别，允许进程或程序执⾏特权指令和访问操作系统的核⼼部分。在核⼼态下，进程可以直接访问硬件资源，执⾏系统调⽤，管理内存、⽂件系统等操作。
- 发生系统调用、异常、中断时、从用户态切换到核心态

### 产生死锁的条件

- 互斥条件：⼀个进程占⽤了某个资源时，其他进程⽆法同时占⽤该资源。
- 请求保持条件：⼀个线程因为请求资源⽽阻塞的时候，不会释放⾃⼰的资源。
- 不可剥夺条件：资源不能被强制性地从⼀个进程中剥夺，只能由持有者⾃愿释放。
- 循环等待：多个进程之间形成⼀个循环等待资源的链  

### 解除死锁：

- 破坏请求与保持条件：⼀次性申请所有的资源。
- 破坏不可剥夺条件：占⽤部分资源的线程进⼀步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
- 破坏循环等待条件：靠按序申请资源来预防。让所有进程按照相同的顺序请求资源，释放资源则反序释放。

### -------------------------------------------------



### MySQL索引

索引是一种数据结构，用于提高数据库表中数据的查询效率。它就像一本书的目录，通过特定的键值来快速定位到相应的数据行。

**作用**：能大大减少数据库在查询时需要扫描的数据量，从而加快查询速度。例如在一个有大量记录的用户表中，若经常根据用户名查询用户信息，为用户名字段建立索引，查询时就可直接定位到对应记录，而无需全表扫描。

**类型**：

- 数据结构角度：常见的有 B - Tree 索引、哈希索引等。B - Tree 索引适用于范围查询和排序操作，哈希索引则在等值查询时性能出色。
- 物理存储角度：聚集索引 -- 数据与索引一起存放，找到了索引就找到了数据。 非聚集索引 -- 数据存储与索引分开存放
- 逻辑角度：
  - 主键索引 -- 不允许有空值，特殊的唯一索引
  - 唯一索引 -- 索引列中的值必须是唯一的，可以为空值
  - 联合索引 -- 多个字段创建的索引， 使用时遵循 最左前缀原则

### 为什么使用B+树做索引

- B+ 树的⾮叶⼦节点不存放实际的记录数据，仅存放索引，数据量相同的情况下，B+树的⾮叶⼦节点可以存放更多的索引，整个树的高度会矮一点，查询底层节点的磁盘 I/O次数会更少。  
- B+ 树所有叶⼦节点间有⼀个链表进⾏连接，范围查询效率高

### 什么时候需要创建索引

- 表的主键字段，会自动建立唯一索引
- 经常用于WHERE查询条件的字段
- 查询中排序的字段
- 与其他表有关联的字段

### 索引失效的场景

- 对索引使用函数
- 对索引使用左 或者 左右模糊匹配
- 对索引进行表达式计算
- 对索引隐式类型转换
- OR 前的条件列是索引列，而在 OR 后的条件列不是索引列

### MySQL事务

事务是由一组 SQL 语句组成的逻辑单元，这些语句要么全部执行成功，要么全部不执行，以保证数据库的一致性。

- **特性**：具有原子性（通过undo log）、一致性、隔离性（通过MVCC，多版本并发控制）和持久性（通过redo log），即 ACID 特性。原子性确保事务中的操作要么都完成，要么都不做；一致性保证事务执行前后数据库的完整性约束得到满足；隔离性防止并发事务之间相互干扰；持久性保证事务一旦提交，其结果就永久保存在数据库中。
- 事务的隔离级别
  - 读未提交 -- 允许事务读取其他事务尚未提交的数据。--  会出现脏读，即一个事务读取到了另一个未提交事务修改的数据
  - 读提交 -- 只能读取已经提交的数据，避免了脏读。--  在一个事务内的多次查询可能会出现不可重复读的情况，即由于其他事务在该事务两次查询之间对数据进行了修改并提交，导致两次查询结果不一致。
  - 可重复读 -- 确保在一个事务内多次读取同一数据时，结果是一致的，解决了不可重复读问题。-- 可能会出现幻读，在一个事务内多次查询某个符合查询条件的「记录数量」，出现前后两次查询到的记录数量不一样的情况
  - 串行化 -- 事务串行执行，就像没有并发一样，避免了所有并发问题。-- 性能开销大

### MVCC机制

⽤于管理多个事务同时访问和修改数据库的数据，⽽不会导致数据不⼀致或冲突。MVCC的核⼼思想是每个事务在数据库中看到的数据版本是事务开始时的⼀个快照，⽽不是实际的最新版本。这使得多个事务可以并发执⾏，⽽不会互相⼲扰 

快照包含四个信息：

- m_ids 当前活跃的所有事务id（所有未提交的事务）
- min_trx_id 当前活跃事务中id最小的，事务id比这个小就代表，再快照开启前，该事务已经提交
- max_trx_id 下⼀个将要分配的事务id（版本链头事务id+1），如果一条记录的事务id**大于等于**这个就代表，快照创建后，该事务才开启，不能访问。（可以查找undo log寻找上一个修改该记录的事务）
- creator_trx_id 创建这个ReadView的事务的id 查询规则

### MySQL锁机制

锁是数据库管理系统用于控制并发访问的一种机制，它允许在同一时间内对特定的数据资源进行排他性或共享性的访问控制。

- **从操作类型上**可分为共享锁（读锁）和排他锁（写锁）。共享锁允许事务对数据进行读操作，多个事务可同时获取共享锁来读取数据；排他锁则用于写操作，一个事务获取排他锁后，其他事务不能再获取该数据的任何锁，直到排他锁被释放。
- **从粒度上**可分为表级锁、行级锁等。表级锁对整个表进行锁定，开销小但并发度低；行级锁只对特定行进行锁定，能支持更高的并发，但开销较大。
- 行锁分为：
  - 记录锁
  - 间隙锁
  - Next-Key Lock，锁定一个范围，并锁定记录本身

### Redis持久化

- AOF ⽇志：每执⾏⼀条写操作命令，就把该命令以追加的⽅式写⼊到⼀个⽂件⾥。Redis刚启动时，会读取该日志来构建数据库
- RDB 快照：将某⼀时刻的内存数据，以⼆进制的⽅式写⼊磁盘；每次执⾏快照，都是把内存中的「**所有数据**」都记录到磁盘中  
- 混合持久化⽅式： Redis 4.0 新增的⽅式，集成了 AOF 和 RBD 的优点；

### -------------------------------------------------



### 单例模式

```C++
class Singleton {
public:
    // 删除拷贝构造函数和赋值操作符
    Singleton(const Singleton&) = delete;
    Singleton& operator=(const Singleton&) = delete;

    // 全局访问点
    static Singleton& getInstance() {
        static Singleton instance; // C++11 保证静态局部变量初始化线程安全
        return instance;
    }

private:
    Singleton() {} // 私有构造函数，使得只有类内部可创建实例
    ~Singleton() {} // 私有析构函数
};
```

双重检查锁定

```C++
class Singleton {
public:
    // 删除拷贝构造函数和赋值操作符
    Singleton(const Singleton&) = delete;
    Singleton& operator=(const Singleton&) = delete;

    // 全局访问点
    static Singleton* getInstance() {
        if (instance == nullptr)
        {
            std::lock_guard<std::mutex> lock(mutex_);
            if (instance == nullptr)
            {
                instance = new Singleton();
            }
        }
        return instance;
    }

private:
    Singleton() {} // 私有构造函数
    ~Singleton() {} // 私有析构函数
    static Singleton *instance;
    static std::mutex mutex_; // 保证无论通过多少个线程调用getInstance()，始终操作同一个mutex_
};

// 静态成员变量需要在类外初始化
Singleton::instance = nullptr;
std::mutex Singleton::mutex_;
```



### 工厂模式

将对象的创建逻辑封装在一个工厂类或工厂方法中，使代码与具体对象的依赖关系解耦

- **解耦对象的创建与使用**，通过统一接口创建不同类型对象
- 简单工厂 --  一个工厂类根据工厂函数的参数创建不同产品
- 工厂方法 --  抽象工厂定义一个创建对象的抽象方法，由具体工厂子类实现该方法来创建产品。
- 抽象工厂 --  工厂基类定义一个创建一系列相关产品的抽象接口，具体工厂（一系列相关产品的不同生厂商）实现该接口来创建产品族。



### Reactor模式

 **I/O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 / 线程**

- 单Reactor单线程
  - Reactor对象通过Select监听事件，如果是连接建立事件，分发给Acceptor对象进行处理，如果是其他事件，交给handler对象进行处理
- 单Reactor多线程
  - reactor对象监听事件，根据事件类型发送给Acceptor对象或者handler对象
  - handler对象会将raad读取到的数据交给子线程进行处理，处理完后子线程会返回结果给handler，handler完成对client的响应。
- 多Reactor多线程
  - 主线程的MainReactor监听**连接建立事件**, 收到事件后通过Acceptor获取连接，将连接分配给某个子线程
  - 子线程的SubReactor将该连接加入IO多路复用进行监听，
  - 该连接有事件发生时，子线程对事件进行处理

### Proactor模式

异步网络模式，感知的是已完成的读写事件



### 异步日志具体介绍

日志库大体分为前端和后端两部分，前端是供应用程序使用的接口，并生成日志消息，后端负责把日志写到文件。每个线程都有自己的前端，整个程序共用一个后端。

如何应对若程序崩溃，那么最后若干日志丢失

- 定期将缓冲区内的日志刷新到硬盘
- 每条内存中的日志消息都带有函数地址

 基本思想：

- 准备两块Buffer：A、B，前端负责往bufferA中填数据，后端负责将bufferB的数据写入文件。当bufferA写满之后，交换A和B，让后端将bufferA的数据写入文件，而前端则往bufferB填入新的日志消息。

实际实现：

- 前端后端各持有两个缓冲区，前端和后端各有一个缓冲区数组，初始时是空的。
- 后端线程被唤醒的条件为：1.超时  2.前端写满了一个或多个buffer
- 后端线程被唤醒后，将前端正在写入的buffer加入到数组中，并将后端空闲的buffer移为前端的写入buffer。后端的缓冲区数组和前端的缓冲区数组交换过后，即可退出临界区，后端继续进行写入文件操作。

### 动态缓冲区具体介绍

Buffer类中记录了读取数据的起始位置、可继续写入的位置。底层使用vector<char>实现。通过这些vector的size以及记录的两个索引，可以计算出可写空间是多少，可读数据是多少。

input Buffer : 从socket读取数据，然后写入input buffer，客户从input buffer读取数据

output Buffer ：客户把数据写入output buffer， 连接从output buffer读取数据写入socket

自动增长策略：需要写入的数据超过当前可用空间时，缓冲区会自动增长

- 首先检查已读数据前面（也就是已经被读过了的数据，readIndex之前）是否有足够的空间
- 如果不足，会对buffer进行resize。
- 如果足够，则移动数据，使得buffer后段留出足够写入的连续空间。

buffer：readFd 

​	要读取的tcp数据大小不可控，使用栈的额外空间

- 栈上准备一个64KB的buf，利用readv读取数据，iovec有两块，第一块指向Buffer的writable字节，第二块指向栈空间，如果读入的数据不多，全部读到Buffer中了，如果数据大于了Buffer的可写空间，那么读入栈上，之后再使用栈上的数据加入到Buffer中。

作用：

- 解决 TCP 粘包 / 拆包问题；通过Buffer存储完整的数据包，等待应用程序按协议解析
- 减少read()`/`write()系统调用次数
- 内存管理优化；读写操作后通过调整索引（`readerIndex`和`writerIndex`）重用内存

### 什么是 one loop per thread，优势是什么

一种在并行计算和多线程编程中的设计模式。它的核心思想是为每个线程分配一个独立的循环任务，使得每个线程专注于处理自己的循环逻辑，从而实现任务的并行执行。

- 每个 `EventLoop` 线程负责处理自己的 I/O 事件，减少线程同步开销
- 每个 `EventLoop` 绑定一个独立的 I/O 多路复用器（如 Linux 的 epoll），减少了单个 epoll 实例的压力。

如何实现：

- 创建loop时记录当前线程 ID，通过`isInLoopThread()`检查调用线程是否合法
- 使用线程局部变量确保每个线程只有一个`EventLoop`实例
- 当需要在其他线程的`EventLoop`中执行任务时，通过`runInLoop()`和`queueInLoop()`方法

### LFU缓存

用 2 个哈希表再加上 N 个双链表才能实现先按照频数再按照时间两个纬度的淘汰策略
哈希表 1：hashNode，节点哈希表，用于快速获取数据中 key 对应的节点信息
哈希表 2：hashFreq，频数双向链表哈希表，为每个访问频数 freq 构造一个双向链表 freqList，并且用哈希表联系二者关系以快速定位。

记录当前缓存中的最小频率。

节点中保存前驱指针和后驱指针以及频率，双向链表结构中保存两个哨兵节点（L，R）。这样通过hashNode找到一个节点后，可以迅速通过其频率找到其所在的链表，并对该节点进行更新。

LFU优化，定期将所有项的频率除以某个系数（50%），模拟“访问热度随时间降低”，避免长期驻留的项频率无限累加。

### 堆的复杂度,为什么定时器使用小根堆

- 插入元素O(logn)
- 删除堆顶元素O(logn)
- 获取堆顶元素O(1)
- 查找元素O(n)

对比其他：

- 无序链表 添加O(1)， 查找最小元素需O(n)
- 红黑树，插入 / 删除 / 查找均为 O (log n)，但获取最小元素需 O (log n)

### epoll为什么优于poll、select

1. **避免重复拷贝 FD 集合**
   - select/poll 每次调用都需将 FD 集合从用户空间拷贝到内核空间
   - epoll 通过`epoll_ctl`预先在内核红黑树中注册 FD，后续`epoll_wait`无需重复拷贝
2. **“就绪过滤” 机制**
   - select/poll 的内核实现需要遍历所有监控的 FD
   - epoll 内核维护一个就绪事件链表，`epoll_wait`直接返回该链表

select：FD 数量受限

- 将 FD 集合从用户空间拷贝到内核空间（O (n) 时间）。
- 内核遍历所有 FD，检查就绪状态（O (n) 时间）。
- 返回就绪 FD 的数量，但不告知具体是哪些 FD

poll：使用`pollfd`数组存储 FD，无固定数量限制

- 同样需将 FD 数组从用户空间拷贝到内核空间（O (n) 时间）。
- 内核遍历所有 FD 检查就绪状态（O (n) 时间）。
- 返回就绪 FD 数量，用户空间需遍历数组判断就绪 FD。

epoll：FD 数量无实质限制

- 增删改 FD 时，通过红黑树高效操作（O (log n) 时间）。
- `epoll_wait`：直接返回就绪 FD 链表，无需遍历所有 FD

### 水平触发与边缘触发

- 水平触发：当文件描述符对应的 IO 缓冲区中存在未读取的数据（读事件）或缓冲区未满（写事件）时，会持续触发事件通知。支持阻塞 / 非阻塞 IO
- 边缘触发：当文件描述符的 IO 状态发生变化时（如从不可读变为可读），仅触发一次事件通知，后续状态持续就绪时不再触发。必须使用非阻塞 IO
- 边缘触发一定要非阻塞IO：
  - 假设在 ET 模式下使用阻塞 IO
  - 若数据未读完，阻塞 IO 会等待后续数据，导致线程卡住；
  - 但由于 ET 模式不会再次触发事件，线程将永久阻塞，导致程序卡死

- 阻塞IO：当进程发起 IO 操作时，如果数据未就绪，进程会被挂起（进入等待状态），直到数据就绪并完成操作后才继续执行。阻塞 IO 会导致当前线程暂停执行，无法处理其他任务，直到 IO 完成
- 非阻塞IO：当进程发起 IO 操作时，如果数据未就绪，系统调用会立即返回（通常返回`EWOULDBLOCK`或`EAGAIN`错误），进程可以继续执行其他任务。进程需主动调用`read()`/`write()`尝试操作，若返回错误则继续执行其他任务，稍后再次尝试。

- 

### protobuf

Protocol Buffers是 Google 开发的一种高效、跨平台、语言无关的数据序列化协议，用于结构化数据的编解码。它通过预定义的消息格式（`.proto` 文件）生成代码，广泛应用于 RPC 框架、数据存储、配置文件等场景。

Json与protobuf的对比：

- protobuf将数据编码成二进制格式，Json则是文本格式
- Json可直接读
- protobuf数据体积小很多
- 都是跨语言支持的

protobuf与json的性能差异原因：

- 数据格式的差异，json基于文本，解析时需要逐字符扫描，protobuf的二进制编码直接按字节流处理
- json是动态结构，每次解析需要实时推断类型，protobuf通过.proto文件预定义类型
- protobuf支持零拷贝解析，直接将字节流按照预定义的结构填充到内存中。

### 项目性能测试

raft项目：

- 并发模拟多个 Clerk 向 KVServer 发送大量 RPC 请求（Put/Get），并记录每个请求的延迟、成功/失败数量，以及最终统计出系统的吞吐量与延迟分布
- 创建多个线程，在一段时间内重复发送get或put请求，最终结果为平均每个请求的延迟为40ms左右。

webServer:

- 使用一款性能测试工具webbench，模拟1000个客户端同时对服务器进行60秒的并发请求，在我的电脑配置上最高QPS（每秒多少请求）可达到3万多。



### 内存泄漏检查工具

- 运行时检测
  - Valgrind -- 检测 内存泄漏、越界访问、使用已释放内存
  - AddressSanitizer -- 内存泄漏、越界访问、使用已释放内存、野指针
- 编译器检测
  - Cppcheck -- 内存泄漏、数组越界、未初始化变量
  - Clang-Tidy  --  未释放的内存、空指针解引用、双重释放  可集成到 IDE
- 原理
  - 编译器检测 -- 通过分析源代码，基于规则推断可能的内存泄漏。
  - 在程序运行时监控内存分配和释放操作，记录状态并检测异常。
    - 在`malloc`/`new`被调用时，插入记录；在`free`/`delete`被调用时，标记记录为已释放
    - 在程序结束时，遍历所有分配记录，未标记为释放的记录即为泄漏

### 跳表

- 跳表在**链表的基础上增加了多层索引**，每一层都是一个有序链表的子集。最底层（Level 0）包含所有节点，而更高层的节点通过 “跳跃” 某些节点来加速查找：
- 跳表使用**随机化机制**决定每个节点的层级：插入节点时，每个节点的层级独立随机生成，不受其他节点影响
- 跳表的查找过程从顶层索引开始，逐层向下搜索：从顶层最左侧节点开始，沿当前层向右查找，直到找到第一个**大于等于目标值**的节点或到达链表末尾。如果当前节点的值等于目标值，则查找成功；否则，下降一层继续搜索。

- 

### 一致性哈希

一致性哈希是一种特殊的哈希算法，在分布式系统中广泛应用。它解决了传统哈希在动态节点环境下的数据迁移和负载均衡问题。

- 传统哈希：当节点数量变化（新增或删除节点）时，几乎所有数据的映射关系都会改变，导致大量数据迁移。
- 一致性哈希：
  - **新增节点**：仅影响新增节点逆时针方向到前一个节点之间的数据。
  - **删除节点**：仅影响被删除节点逆时针方向到前一个节点之间的数据，这些数据将迁移到下一个节点

实现：

- 将整个哈希空间（通常是 0~2^32-1）组织成一个虚拟环。
- 将服务器节点（如 IP 地址）哈希到环上的某个位置
- 将数据（如键值对）哈希到环上，顺时针找到第一个节点作为存储位置。

优势：

- 当节点数量变化时，仅需迁移环上相邻节点间的数据，迁移量与总数据量呈线性关系（而非传统哈希的 O (N)）。
- 负载均衡 --  通过虚拟节点（Virtual Nodes）技术，将一个物理节点映射为多个虚拟节点，均匀分布在环上，避免数据倾斜。

### 计算机

1. 进程、线程和协程是什么?它们之间有什么区别和联系？什么场景下会选择多线程?什么场景下会考虑使用协程?
2. 描述一下堆和栈的区别。函数调用是如何使用栈的？为什么堆上的内存分配比栈慢?
3. 什么是死锁？产生死锁的四个必要条件是什么?如何预防或避免死锁？
4. 什么是虚拟内存?它解决了什么问题？什么是TLB(快表)？它的作用是什么？为什么需要多级页表？
5. I/O模型有哪些？阻塞(Blocking)、非阻塞(Non-blocking)、同步(Synchronous)、异步(Asynchronous)之间有什么区别？ select/pollepoll的区别是什么? epoll 的优势在哪里(LT/ET模式)？
6. 解释一下Reactor和 Proactor两种/O设计模式。
7. 常见的 CPU 调度算法有哪些?各自适用于什么场景？
8. 什么是CPU缓存一致性？可以简单解释一下 MESI协议吗？什么是“伪共享(False Sharing)?它会对性能产生什么影响？在代码层面如何避免？
9. MMU的功能和作用
10. 什么是“缺页异常”?
11. 自旋锁和互斥锁的差别

### 数据结构

1. 哈希表(Hash Table/Map)是如何工作的？如何解决哈希冲突? Go的map是如何实现的?它在并发环境下是安全的吗？
2. 什么是跳表(Skip List)？它解决了什么问题?
3. 什么是二叉搜索树(BST)？它有什么问题？如何改进?
4. 什么是一致性哈希？它主要解决了什么问题?

### 计算机网络

1. tcp/udp区别， http协议描述， ip协议是什么
2. http和https的客户端和服务器区别
3. 为什么握手是三次而不是两次？为什么挥手是四次?
4. TCP的 TIME WAIT状态有什么作用？如果服务器上有大量 TIME_WAIT状态的连接，应该如何优化？
5. TCP的流量控制和拥塞控制有什么区别？
6. HTTP/1.1、HTTP/2、 HTTP/3的主要区别是什么?
7. 简单描述一下HTTPS的工作原理,特别是TLS握手过程。
8. RESTful API和 RPC(如gRPC)有什么区别?在什么场景下应该如何选择？

### GO

1. Goroutine是什么?它和线程有什么区别?
2. 介绍一下 Go的Channel,以及它的基本用法。
3. 简单描述-下 Go的GMP 调度模型。什么情况下 Goroutine 会发生抢占?
4. 什么是逃逸分析？在Go中，变量在什么情况下会从栈逃逸到堆?如何通过编译指令查看逃逸分析的结果?
5. go垃圾回收机制，减少GC停顿时间的优化思路。
6. 你在项目中是如何进行错误处理的?谈谈你对error 和 panic/exception 的理解。
7. 谈谈你对接口(Interface)和泛型(Generics)的理解，它们分别解决了什么问题？在GO中,空接口 interfacef和 any有什么关系？使用泛型相比于使用接口有什么优势?
8. goroutine泄露
9. go的context类的应用场景
10. go的内存模型
    - 如何理解Happens Before
    - 如何理解 Don't communicate by sharing memory; share memory by communicating
11. slice实现，map实现
12. 父协程调用多个子协程，父协程会传递context给子协程，要求在不改变接口和尽量少改动代码的前提下将子协程的数据传递给父协程
13. nil与空值的区别
14. 性能优化:工具-trace, pprof, benchmark。性能优化技巧
15. 函数是值传递还是引用传递
16. 缓冲、无缓冲 chan的区别
17. 如何实现deep copy
18. init的执行顺序
19. 子协程panic为何没法被父协程recover
20. Finalizer的作用
21. timer.Ticker是否精准
22. go的对象池方案及解决的问题

### 云服务和分布式

1. Kubernetes (K8s)中的 Pod, Deployment, Service分别是什么? 
2. 什么是容器?什么是镜像?Docker的基本工作原理是什么? 
3. 微服务架构中，服务发现是如何实现的? 
4. 什么是熔断、降级和限流?它们分别解决了什么问题? 
5. 消息队列 (如Kafka)在系统中通常扮演什么角色?它的“分区"和“消费者组”是什么概念? 
6. 缓存的穿透、击穿、雪崩分别是什么?如何应对？
